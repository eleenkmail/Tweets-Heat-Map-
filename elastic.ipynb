{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from datetime import datetime, timezone\n",
    "import uuid\n",
    "from dateutil import parser\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create python client for elasticsearch\n",
    "es = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name =\"tweets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m1/fg0zsph94pj5b7vblgt01b580000gn/T/ipykernel_5663/4044851082.py:1: DeprecationWarning: Using positional arguments for APIs is deprecated and will be disabled in 8.0.0. Instead use only keyword arguments for all APIs. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  if es.indices.exists(index_name):\n"
     ]
    }
   ],
   "source": [
    "if es.indices.exists(index_name):\n",
    "     es.indices.delete(index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  mapping the index\n",
    "body = {\n",
    "  \"mappings\": {\n",
    "        \"properties\": {\n",
    "          \"id\":{\n",
    "              \"type\": \"keyword\",\n",
    "              \"ignore_above\": 256\n",
    "              },\n",
    "\n",
    "          \"text\": {\n",
    "              \"type\" : \"text\",\n",
    "              \"analyzer\": \"standard\",    \n",
    "              },\n",
    "\n",
    "          \"date\": {\n",
    "              \"type\": \"date\",\n",
    "              },\n",
    "\n",
    "          \"location\":{\n",
    "              \"type\" : \"geo_point\"\n",
    "              },\n",
    "\n",
    "    \n",
    "              } }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  query return the docs contain word \"flood\" at specific range of time at boundary box coordenates\n",
    "query_body =  {\"query\":{\n",
    "      \"bool\": {\n",
    "        \"must\": [\n",
    "          {\n",
    "            \"match\" : {\n",
    "              \"text\":{\n",
    "              \"query\":\"flood\" \n",
    "          }}},\n",
    "          {\n",
    "          \"range\": {\n",
    "          \"date\": {\n",
    "          \"time_zone\": \"+00:00\",  \n",
    "          \"gte\": \"2013-01-01T22:10:00\", \n",
    "          \"lte\": \"2013-12-20T22:12:00\"                  \n",
    "      }}},\n",
    "        \n",
    "        {\n",
    "          \"geo_bounding_box\": {\n",
    "            \"location\": {\n",
    "              \n",
    "              \"top_left\": {\n",
    "                \"lat\": 90.000,\n",
    "                \"lon\": -180.000\n",
    "              },\n",
    "              \"bottom_right\": {\n",
    "                \"lat\": -90.000,\n",
    "                \"lon\": 180.000\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }   \n",
    "        ]\n",
    "      }}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m1/fg0zsph94pj5b7vblgt01b580000gn/T/ipykernel_5663/866937466.py:2: DeprecationWarning: The 'body' parameter is deprecated for the 'create' API and will be removed in a future version. Instead use API parameters directly. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  es.indices.create(index=index_name, ignore=400, body=body)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'tweets'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  create index with \"tweet name\"\n",
    "es.indices.create(index=index_name, ignore=400, body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "#  read the json file of tweets and insert it to the tweet index\n",
    "def generator():\n",
    "    \n",
    "    index_name = 'tweets'\n",
    "    i=0\n",
    "    for line in open('../data/boulder_flood_geolocated_tweets-1.json', 'r' ,encoding='utf-8'):\n",
    "           \n",
    "            data_ = json.loads(line)\n",
    "\n",
    "            # convert time with \"yyyy-mm-ddThh:mm:ss\" without the time zone\n",
    "            tweet_date = parser.parse(data_[\"created_at\"])\n",
    "            data_[\"created_at\"] = tweet_date.replace(tzinfo=None)\n",
    "            \n",
    "            doc = { \n",
    "                 '_index': index_name,\n",
    "                    \"id\" : int(data_[\"id\"]),\n",
    "                    \"text\" : data_[\"text\"],\n",
    "                    \"date\" : data_[\"created_at\"] ,\n",
    "                    \"location\" : data_[\"coordinates\"],\n",
    "                            }\n",
    "            i+=1\n",
    "            if i% 4000 == 0:\n",
    "                 time.sleep(2)\n",
    "\n",
    "            yield doc\n",
    "            \n",
    "\n",
    "            \n",
    "                \n",
    "         \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18821, [])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helpers.bulk(es, generator(), chunk_size=4000, raise_on_error=True ,raise_on_exception=True, yield_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m1/fg0zsph94pj5b7vblgt01b580000gn/T/ipykernel_5663/1477574662.py:2: DeprecationWarning: The 'body' parameter is deprecated for the 'search' API and will be removed in a future version. Instead use API parameters directly. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  result = es.search(\n"
     ]
    }
   ],
   "source": [
    "# search query \n",
    "result = es.search(\n",
    "      index = index_name,\n",
    "      body = query_body\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': {'value': 194, 'relation': 'eq'},\n",
       " 'max_score': 6.3621383,\n",
       " 'hits': [{'_index': 'tweets',\n",
       "   '_id': '0G5yJoUBL-qfb7xN22D0',\n",
       "   '_score': 6.3621383,\n",
       "   '_source': {'id': 378611244619415552,\n",
       "    'text': 'Flood? What flood? #Denver #cowx http://t.co/TgKowYe5lr',\n",
       "    'date': '2013-09-13T20:08:49',\n",
       "    'location': {'type': 'Point', 'coordinates': [-104.989221, 39.743126]}}},\n",
       "  {'_index': 'tweets',\n",
       "   '_id': '425yJoUBL-qfb7xN3mwo',\n",
       "   '_score': 6.1421237,\n",
       "   '_source': {'id': 378292312524455936,\n",
       "    'text': 'We\\'ve finally admitted it is the 100yr flood #noshit â€œ@dailycamera: Flood expert: Boulder experiencing a 100-year flood. #boulderflood\"',\n",
       "    'date': '2013-09-12T23:01:30',\n",
       "    'location': {'type': 'Point',\n",
       "     'coordinates': [-89.99813896, 35.14676299]}}},\n",
       "  {'_index': 'tweets',\n",
       "   '_id': '_m5yJoUBL-qfb7xN3nQr',\n",
       "   '_score': 5.910203,\n",
       "   '_source': {'id': 378068649430380544,\n",
       "    'text': \"Hello 2am. I'm up making sure our house doesn't flood. #boulderflood #fortcollins #larimerco #flood\",\n",
       "    'date': '2013-09-12T08:12:44',\n",
       "    'location': {'type': 'Point',\n",
       "     'coordinates': [-105.0688901, 40.54931461]}}},\n",
       "  {'_index': 'tweets',\n",
       "   '_id': 'cW5yJoUBL-qfb7xN22n5',\n",
       "   '_score': 5.673731,\n",
       "   '_source': {'id': 378369169294491649,\n",
       "    'text': 'Oh crap, flood sirens again!! #boulderflood',\n",
       "    'date': '2013-09-13T04:06:54',\n",
       "    'location': {'type': 'Point',\n",
       "     'coordinates': [-105.24686208, 40.03594844]}}},\n",
       "  {'_index': 'tweets',\n",
       "   '_id': 'nG5yJoUBL-qfb7xN3m4o',\n",
       "   '_score': 5.657576,\n",
       "   '_source': {'id': 378249198694445056,\n",
       "    'text': 'Flash Flood Warning #flood #boulder #colorado #cu #rain #storm #water #waterfall #campus: Courtesy @b... http://t.co/ZOGqbpGOCL #iReport',\n",
       "    'date': '2013-09-12T20:10:11',\n",
       "    'location': {'type': 'Point', 'coordinates': [-105.2705456, 40.0149856]}}},\n",
       "  {'_index': 'tweets',\n",
       "   '_id': '0W5yJoUBL-qfb7xN3m4o',\n",
       "   '_score': 5.657576,\n",
       "   '_source': {'id': 378249200980328449,\n",
       "    'text': 'Flash Flood Warning #flood #boulder #colorado #cu #rain #storm #water #waterfall #campus: Courtesy @brandash O... http://t.co/eD1WrOzyyd',\n",
       "    'date': '2013-09-12T20:10:11',\n",
       "    'location': {'type': 'Point', 'coordinates': [-105.2705456, 40.0149856]}}},\n",
       "  {'_index': 'tweets',\n",
       "   '_id': 'X25yJoUBL-qfb7xN22L1',\n",
       "   '_score': 5.558278,\n",
       "   '_source': {'id': 378567108579586048,\n",
       "    'text': '#boulder #flood @ Flatiron Subaru http://t.co/SXCRKdzepL',\n",
       "    'date': '2013-09-13T17:13:26',\n",
       "    'location': {'type': 'Point', 'coordinates': [-105.21330888, 40.015358]}}},\n",
       "  {'_index': 'tweets',\n",
       "   '_id': 'ZG5yJoUBL-qfb7xN22L1',\n",
       "   '_score': 5.558278,\n",
       "   '_source': {'id': 378566632496701440,\n",
       "    'text': '#boulder #flood @ Flatiron Subaru http://t.co/kxqFRJvWch',\n",
       "    'date': '2013-09-13T17:11:33',\n",
       "    'location': {'type': 'Point', 'coordinates': [-105.21330888, 40.015358]}}},\n",
       "  {'_index': 'tweets',\n",
       "   '_id': 'k25yJoUBL-qfb7xN22L1',\n",
       "   '_score': 5.558278,\n",
       "   '_source': {'id': 378564950291406848,\n",
       "    'text': '#boulder #flood @ Flatiron Subaru http://t.co/bkZolbg9tj',\n",
       "    'date': '2013-09-13T17:04:52',\n",
       "    'location': {'type': 'Point', 'coordinates': [-105.21330888, 40.015358]}}},\n",
       "  {'_index': 'tweets',\n",
       "   '_id': 'mm5yJoUBL-qfb7xN22L1',\n",
       "   '_score': 5.558278,\n",
       "   '_source': {'id': 378565440903344128,\n",
       "    'text': '#boulder #flood @ Flatiron Subaru http://t.co/efctTp10tB',\n",
       "    'date': '2013-09-13T17:06:49',\n",
       "    'location': {'type': 'Point',\n",
       "     'coordinates': [-105.21330888, 40.015358]}}}]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# documents resulted from query\n",
    "result['hits']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a48e03d4cd8e5e9f1eeb4bcbb42166ac2de80b9979eba71b6a015e15563521bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
